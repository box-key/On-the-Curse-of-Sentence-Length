{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization Cell\n",
    "path = 'C:\\\\Users\\\\under\\\\Jupyter-Projects\\\\My-Research\\\\On-the-Curse-of-Sentence-Length\\\\data-bin\\\\out_reduced_transformer.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\under\\Jupyter-Projects\\My-Research\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from models import ModelEvaluation as me\n",
    "from models.utils import splits as sp\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29838, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = me.loadFairseqOutput(path)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =me.splitDatabyFractionOfUnknowns(output, choice='src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 0: 8827 sentences\n",
      "Key 1: 14905 sentences\n",
      "Key 2: 4707 sentences\n",
      "Key 3: 926 sentences\n",
      "Key 4: 235 sentences\n",
      "Key 5: 157 sentences\n",
      "Key 6: 52 sentences\n",
      "Key 7: 8 sentences\n",
      "Key 8: 0 sentences\n",
      "Key 9: 21 sentences\n"
     ]
    }
   ],
   "source": [
    "for key, val in data.items():\n",
    "    print(f'Key {key}: {len(val)} sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unk 0%: 14336 sentences\n",
      "Unk 10%: 27817 sentences\n",
      "Unk 20%: 5746 sentences\n",
      "Unk 30%: 887 sentences\n",
      "Unk 40%: 217 sentences\n",
      "Unk 50%: 153 sentences\n",
      "Unk 60%: 57 sentences\n",
      "Unk 70%: 18 sentences\n",
      "Unk 80%: 4 sentences\n",
      "Unk 90%: 17 sentences\n"
     ]
    }
   ],
   "source": [
    "output_balanced = me.loadFairseqOutput('C:\\\\Users\\\\under\\\\Jupyter-Projects\\\\My-Research\\\\On-the-Curse-of-Sentence-Length\\\\data-bin\\\\out_balanced_transformer.txt')\n",
    "data_fracunk =sp.splitDatabyFractionOfUnknowns(output_balanced, choice='src')\n",
    "for key, val in sorted(data_fracunk.items(), key=lambda x: x[0]):\n",
    "    print(f'Unk {key*10}%: {len(val)} sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 unks: 22565 sentences\n",
      "5 unks: 18702 sentences\n",
      "10 unks: 5709 sentences\n",
      "15 unks: 1517 sentences\n",
      "20 unks: 403 sentences\n",
      "25 unks: 144 sentences\n",
      "30 unks: 71 sentences\n",
      "35 unks: 47 sentences\n",
      "40 unks: 30 sentences\n",
      "45 unks: 11 sentences\n",
      "50 unks: 15 sentences\n",
      "55 unks: 7 sentences\n",
      "60 unks: 2 sentences\n",
      "65 unks: 1 sentences\n",
      "70 unks: 3 sentences\n",
      "75 unks: 2 sentences\n",
      "80 unks: 1 sentences\n",
      "85 unks: 5 sentences\n",
      "90 unks: 2 sentences\n",
      "95 unks: 1 sentences\n",
      "100 unks: 1 sentences\n",
      "105 unks: 2 sentences\n",
      "110 unks: 1 sentences\n",
      "115 unks: 2 sentences\n",
      "125 unks: 3 sentences\n",
      "140 unks: 1 sentences\n",
      "160 unks: 1 sentences\n",
      "170 unks: 1 sentences\n",
      "175 unks: 1 sentences\n",
      "195 unks: 1 sentences\n"
     ]
    }
   ],
   "source": [
    "tick=5\n",
    "data_numunk =sp.splitDatabyNumberOfUnknowns(output_balanced, tick=tick, choice='src')\n",
    "for key, val in sorted(data_numunk.items(), key=lambda x: x[0]):\n",
    "    print(f'{key*tick} unks: {len(val)} sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 words: 442 sentences\n",
      "10 words: 2178 sentences\n",
      "20 words: 3450 sentences\n",
      "30 words: 3842 sentences\n",
      "40 words: 3787 sentences\n",
      "50 words: 3152 sentences\n",
      "60 words: 2486 sentences\n",
      "70 words: 2199 sentences\n",
      "80 words: 2978 sentences\n",
      "90 words: 4430 sentences\n",
      "100 words: 4572 sentences\n",
      "110 words: 3823 sentences\n",
      "120 words: 2640 sentences\n",
      "130 words: 1932 sentences\n",
      "140 words: 1211 sentences\n",
      "150 words: 900 sentences\n",
      "160 words: 724 sentences\n",
      "170 words: 620 sentences\n",
      "180 words: 622 sentences\n",
      "190 words: 638 sentences\n",
      "200 words: 538 sentences\n",
      "210 words: 485 sentences\n",
      "220 words: 375 sentences\n",
      "230 words: 267 sentences\n",
      "240 words: 187 sentences\n",
      "250 words: 146 sentences\n",
      "260 words: 120 sentences\n",
      "270 words: 102 sentences\n",
      "280 words: 79 sentences\n",
      "290 words: 54 sentences\n",
      "300 words: 40 sentences\n",
      "310 words: 30 sentences\n",
      "320 words: 25 sentences\n",
      "330 words: 35 sentences\n",
      "340 words: 18 sentences\n",
      "350 words: 9 sentences\n",
      "360 words: 11 sentences\n",
      "370 words: 13 sentences\n",
      "380 words: 8 sentences\n",
      "390 words: 12 sentences\n",
      "400 words: 6 sentences\n",
      "410 words: 4 sentences\n",
      "420 words: 11 sentences\n",
      "430 words: 5 sentences\n",
      "440 words: 7 sentences\n",
      "450 words: 3 sentences\n",
      "460 words: 1 sentences\n",
      "470 words: 1 sentences\n",
      "480 words: 1 sentences\n",
      "490 words: 4 sentences\n",
      "500 words: 4 sentences\n",
      "510 words: 1 sentences\n",
      "520 words: 2 sentences\n",
      "550 words: 3 sentences\n",
      "560 words: 1 sentences\n",
      "580 words: 2 sentences\n",
      "600 words: 1 sentences\n",
      "620 words: 1 sentences\n",
      "660 words: 1 sentences\n",
      "680 words: 1 sentences\n",
      "690 words: 1 sentences\n",
      "710 words: 1 sentences\n",
      "730 words: 2 sentences\n",
      "760 words: 1 sentences\n",
      "810 words: 1 sentences\n",
      "840 words: 1 sentences\n",
      "930 words: 1 sentences\n",
      "1010 words: 1 sentences\n",
      "1260 words: 1 sentences\n",
      "1330 words: 2 sentences\n"
     ]
    }
   ],
   "source": [
    "tick = 10\n",
    "data_senlen =me.splitDatabySentenceLength(output_balanced, tick=5, choice='src')\n",
    "for key, val in sorted(data_senlen.items(), key=lambda x: x[0]):\n",
    "    print(f'{key*tick} words: {len(val)} sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
