{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization Cell\n",
    "path_data = '/home/compling6/knemoto/Datasets/Europarl_fr-en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.Model_Evaluation as me\n",
    "from models.TrainModel import TrainModel\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from models.MyTranslationDataset import prepareTranslationData\n",
    "from torchtext.datasets import TranslationDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "spacy_fr = spacy.load('fr')\n",
    "\n",
    "def tokenize_fr(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_fr, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "train, val, test = TranslationDataset.splits(exts=('.fr','.en'),\n",
    "                                             fields=(SRC,TRG),\n",
    "                                             path=path_data)\n",
    "\n",
    "SRC.build_vocab(train, min_freq = 2)\n",
    "TRG.build_vocab(train, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, val_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train, val, test), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GRU\n",
    "\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "model1 = GRU.Seq2Seq(input_dim=INPUT_DIM, \n",
    "                      enc_emb_dim=ENC_EMB_DIM, \n",
    "                      hid_dim=HID_DIM, \n",
    "                      enc_dropout=ENC_DROPOUT,\n",
    "                      output_dim=OUTPUT_DIM, \n",
    "                      dec_emb_dim=DEC_EMB_DIM,\n",
    "                      dec_dropout=DEC_DROPOUT,\n",
    "                      device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model1.parameters(), lr=0.03, weight_decay=0.0001, betas=(0.9,0.99))\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "train_GRU = TrainModel(model=model1,\n",
    "                       train_iterator=train_iterator,\n",
    "                       val_iterator=val_iterator,\n",
    "                       optimizer=optimizer,\n",
    "                       criterion=criterion,\n",
    "                       model_type='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "train_GRU.epoch(n_epochs=N_EPOCHS, clip=CLIP, model_name='vanilla-model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_fr, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            include_lengths = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "train, val, test = TranslationDataset.splits(exts=('.fr','.en'),\n",
    "                                             fields=(SRC,TRG),\n",
    "                                             path=path_data)\n",
    "\n",
    "SRC.build_vocab(train, min_freq = 2)\n",
    "TRG.build_vocab(train, min_freq = 2)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, val_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train, val, test), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     sort_within_batch = True,\n",
    "     sort_key = lambda x : len(x.src),\n",
    "     device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BiGRUwithAttention\n",
    "\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "model2 = BiGRUwithAttention.Seq2Seq(input_dim=INPUT_DIM, \n",
    "                                  enc_emb_dim=ENC_EMB_DIM, \n",
    "                                  enc_hid_dim=ENC_HID_DIM,\n",
    "                                  enc_dropout=ENC_DROPOUT,\n",
    "                                  output_dim=OUTPUT_DIM, \n",
    "                                  dec_emb_dim=DEC_EMB_DIM,\n",
    "                                  dec_hid_dim=DEC_HID_DIM,\n",
    "                                  dec_dropout=DEC_DROPOUT,\n",
    "                                  src_pad_idx=SRC_PAD_IDX,\n",
    "                                  device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model2.parameters(), lr=0.03, weight_decay=0.0001, betas=(0.9,0.99))\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "train_AttentionGRU = TrainModel(model=model2,\n",
    "                         train_iterator=train_iterator,\n",
    "                         val_iterator=val_iterator,\n",
    "                         optimizer=optimizer,\n",
    "                         criterion=criterion,\n",
    "                         model_type='Attention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "train_AttentionGRU.epoch(n_epochs=N_EPOCHS, clip=CLIP,model_name='att-model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_fr, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = True)\n",
    "\n",
    "train, val, test = TranslationDataset.splits(exts=('.fr','.en'),\n",
    "                                             fields=(SRC,TRG),\n",
    "                                             path=path_data)\n",
    "\n",
    "SRC.build_vocab(train, min_freq = 2)\n",
    "TRG.build_vocab(train, min_freq = 2)\n",
    "\n",
    "train_iterator, val_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train, val, test), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Transformer\n",
    "\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_HID_DIM = 256\n",
    "DEC_HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "model3 = Transformer.Seq2Seq(input_dim=INPUT_DIM, \n",
    "                                  enc_hid_dim=ENC_HID_DIM,\n",
    "                                  enc_layers=ENC_LAYERS,\n",
    "                                  enc_heads=ENC_HEADS,\n",
    "                                  enc_pf_dim=ENC_PF_DIM,\n",
    "                                  enc_dropout=ENC_DROPOUT,\n",
    "                                  output_dim=OUTPUT_DIM,\n",
    "                                  dec_hid_dim=DEC_HID_DIM,\n",
    "                                  dec_layers=DEC_LAYERS,\n",
    "                                  dec_heads=DEC_HEADS,\n",
    "                                  dec_pf_dim=DEC_PF_DIM,\n",
    "                                  dec_dropout=DEC_DROPOUT,\n",
    "                                  src_pad_idx=SRC_PAD_IDX,\n",
    "                                  trg_pad_idx=TRG_PAD_IDX, \n",
    "                                  device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.apply(init_weights)\n",
    "optimizer = optim.Adam(model3.parameters(), lr=0.03, weight_decay=0.0001, betas=(0.9,0.99))\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "train_Transformer = TrainModel(model=model3,\n",
    "                         train_iterator=train_iterator,\n",
    "                         val_iterator=val_iterator,\n",
    "                         optimizer=optimizer,\n",
    "                         criterion=criterion,\n",
    "                         model_type='Transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "train_Transformer.epoch(n_epochs=N_EPOCHS, clip=CLIP, model_name='transformer-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
