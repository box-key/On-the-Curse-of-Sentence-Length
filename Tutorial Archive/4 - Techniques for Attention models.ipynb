{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            include_lengths = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
    "                                                    fields = (SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "All elements in the batch need to be sorted by their non-padded lengths in descending order\n",
    "i.e. the first sentence in the batch needs to be the longest.\n",
    "\n",
    "sort_within_batch which tells the iterator that the contents of the batch need to be sorted\n",
    "sort_key a function which tells the iterator how to sort the elements in the batch.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     # Enable sorting within a batch\n",
    "     sort_within_batch = True,\n",
    "     # Tell iterator how to sort elements in a batch\n",
    "     sort_key = lambda x : len(x.src),\n",
    "     device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Reference: https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch\n",
    "\n",
    "When training RNN (LSTM or GRU or vanilla-RNN), it is difficult to batch the variable length sequences. For ex: if length of sequences in a size 8 batch is [4,6,8,5,4,3,7,8], you will pad all the sequences and that will results in 8 sequences of length 8. You would end up doing 64 computation (8x8), but you needed to do only 45 computations. Moreover, if you wanted to do something fancy like using a bidirectional-RNN it would be harder to do batch computations just by padding and you might end up doing more computations than required.\n",
    "\n",
    "Instead, pytorch allows us to pack the sequence, internally packed sequence is a tuple of two lists. One contains the elements of sequences. Elements are interleaved by time steps (see example below) and other contains the size of each sequence the batch size at each step. This is helpful in recovering the actual sequences as well as telling RNN what is the batch size at each time step. This has been pointed by @Aerin. This can be passed to RNN and it will internally optimize the computations.\n",
    "\n",
    "I might have been unclear at some points, so let me know and I can add more explanations.\n",
    "\n",
    "** Padding is a way to make all the senteces the same legnth by adding extra empty tokens (pads). Packing is way to tell RNN the actual length of padded sentences to reduce the computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4]],\n",
      "\n",
      "        [[10, 10],\n",
      "         [20, 20],\n",
      "         [ 0,  0],\n",
      "         [ 0,  0]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 1,  1],\n",
       "        [10, 10],\n",
       "        [ 2,  2],\n",
       "        [20, 20],\n",
       "        [ 3,  3],\n",
       "        [ 4,  4]]), batch_sizes=tensor([2, 2, 1, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_batch = [torch.tensor([[1, 1],\n",
    "                           [2, 2],\n",
    "                           [3, 3],\n",
    "                           [4, 4]]),\n",
    "             torch.tensor([[10, 10],\n",
    "                           [20, 20]])]\n",
    "\n",
    "seq_lens = [4, 2]\n",
    "padded_seq_batch = torch.nn.utils.rnn.pad_sequence(seq_batch, batch_first=True)\n",
    "print(padded_seq_batch)\n",
    "torch.nn.utils.rnn.pack_padded_sequence(padded_seq_batch, lengths=seq_lens, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        # it takes enc_hid_dim*2 cuz it's bidirectional\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_len):\n",
    "        \n",
    "        # src = [src len, batch size]\n",
    "        # src_len = [batch size]\n",
    "        # First, embed sentences in a batch\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        # embedded = [src len, batch size, emb dim]\n",
    "        # pack_padded_sequence takes embedded sentences as input, and returns packed embedded sentences\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n",
    "        \n",
    "        # Pass packed embeddings to avoid unnecessary computation\n",
    "        # packed_outputs is a packed sequence containing all hidden states\n",
    "        # hidden is now from the final non-padded element in the batch\n",
    "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
    "                                 \n",
    "        # outputs is now a non-packed sequence, all hidden states obtained\n",
    "        # when the input is a pad token are all zeros\n",
    "        # outputs will be used in attention\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
    "            \n",
    "            \n",
    "        #outputs = [src len, batch size, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs are always from the last layer\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        # Concatenate forward and backward contexts, which will be used as initial state in decoder\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        \n",
    "        #outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we allowed this module to \"pay attention\" to padding tokens within the source sentence. However, using masking, we can force the attention to only be over non-padding elements.\n",
    "This is a [batch size, source sentence length] tensor that is 1 when the source sentence token is not a padding token, and 0 when it is a padding token. \n",
    "For example, if the source sentence is: [\"hello\", \"how\", \"are\", \"you\", \"?\", <pad>, <pad>], then the mask would be [1, 1, 1, 1, 1, 0, 0].\n",
    "We apply the mask after the attention has been calculated, but before it has been normalized by the softmax function.\n",
    "Masking is applied to ensure that no attention is payed to pad tokens in the source sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        # calculate attention weights using all the hidden states from encoder and previous state in decoder\n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        # calculate weighted sum of attentional vector; this value will be normalized by softmax later\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "  \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        \n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "        # First, calculate weighted sum of attention; this will be asked later\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        # attention = [batch size, src len]\n",
    "        # mask = [batch size, src sentence len], 0 if a token is pad, otherwise 1\n",
    "        # the second arguemnt of masked_fill is condition, and the second one is the return value if condition meets\n",
    "        # if a hidden state is masked, it gives infinitesimal value so decoder can avoid paying attention to pad tokens\n",
    "        attention = attention.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        return F.softmax(attention, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    # forward takes mask as argument\n",
    "    def forward(self, input, hidden, encoder_outputs, mask):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #mask = [batch size, src len]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs, mask)\n",
    "                \n",
    "        #a = [batch size, src len]\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        #a = [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        #output = [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # src_pad_idx = the index of pad token in source vocab\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def create_mask(self, src):\n",
    "        # mask takes a list of tokens\n",
    "        # it returns 1 if an element is not pad, otherwise 0\n",
    "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #src_len = [batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "                    \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        # hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        # must pass src_len to encoder so encoder can pack padded sentences\n",
    "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        # mask source sentences so attention won't be paid to pad tokens\n",
    "        mask = self.create_mask(src)\n",
    "\n",
    "        #mask = [batch size, src len]\n",
    "                \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden state, all encoder hidden states \n",
    "            #  and mask\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(SRC.pad_token)\n",
    "print(SRC.vocab.stoi[SRC.pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7855, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        # batch contains src_len values\n",
    "        # src_len stores the length of each sentence in src\n",
    "        # src = [src length, batch size]\n",
    "        src, src_len = batch.src\n",
    "#         print(src)\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, src_len, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src, src_len = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, src_len, trg, 0) #turn off teacher forcing\n",
    "            \n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 45s\n",
      "\tTrain Loss: 5.188 | Train PPL: 179.069\n",
      "\t Val. Loss: 4.909 |  Val. PPL: 135.457\n",
      "Epoch: 02 | Time: 0m 45s\n",
      "\tTrain Loss: 4.272 | Train PPL:  71.656\n",
      "\t Val. Loss: 4.363 |  Val. PPL:  78.473\n",
      "Epoch: 03 | Time: 0m 45s\n",
      "\tTrain Loss: 3.496 | Train PPL:  32.998\n",
      "\t Val. Loss: 3.646 |  Val. PPL:  38.334\n",
      "Epoch: 04 | Time: 0m 46s\n",
      "\tTrain Loss: 2.907 | Train PPL:  18.306\n",
      "\t Val. Loss: 3.412 |  Val. PPL:  30.311\n",
      "Epoch: 05 | Time: 0m 46s\n",
      "\tTrain Loss: 2.476 | Train PPL:  11.898\n",
      "\t Val. Loss: 3.300 |  Val. PPL:  27.113\n",
      "Epoch: 06 | Time: 0m 45s\n",
      "\tTrain Loss: 2.172 | Train PPL:   8.773\n",
      "\t Val. Loss: 3.254 |  Val. PPL:  25.890\n",
      "Epoch: 07 | Time: 0m 46s\n",
      "\tTrain Loss: 1.940 | Train PPL:   6.957\n",
      "\t Val. Loss: 3.209 |  Val. PPL:  24.757\n",
      "Epoch: 08 | Time: 0m 46s\n",
      "\tTrain Loss: 1.742 | Train PPL:   5.711\n",
      "\t Val. Loss: 3.218 |  Val. PPL:  24.984\n",
      "Epoch: 09 | Time: 0m 46s\n",
      "\tTrain Loss: 1.565 | Train PPL:   4.782\n",
      "\t Val. Loss: 3.329 |  Val. PPL:  27.917\n",
      "Epoch: 10 | Time: 0m 46s\n",
      "\tTrain Loss: 1.432 | Train PPL:   4.189\n",
      "\t Val. Loss: 3.368 |  Val. PPL:  29.025\n"
     ]
    }
   ],
   "source": [
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.201 | Test PPL:  24.552 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut4-model.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
    "\n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('de')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "\n",
    "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
    "\n",
    "    mask = model.create_mask(src_tensor)\n",
    "        \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
    "    \n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
    "\n",
    "        attentions[i] = attention\n",
    "            \n",
    "        pred_token = output.argmax(1).item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "        # if the prob of eos is the highest, stop generating sentence\n",
    "        # greedy search in this function\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]\n",
    "\n",
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                       rotation=45)\n",
    "    ax.set_yticklabels(['']+translation)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['eine', 'frau', 'mit', 'schwarzem', 'oberteil', 'und', 'brille', 'streut', 'puderzucker', 'auf', 'einem', 'gugelhupf', '.']\n",
      "trg = ['a', 'lady', 'in', 'a', 'black', 'top', 'with', 'glasses', 'is', 'sprinkling', 'powdered', 'sugar', 'on', 'a', 'bundt', 'cake', '.']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 15\n",
    "\n",
    "src = vars(train_data.examples[example_idx])['src']\n",
    "trg = vars(train_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg = ['a', 'woman', 'in', 'a', 'black', 'shirt', 'and', 'glasses', 'sprinkling', 'sprinkling', 'powdered', 'powdered', 'powdered', 'a', '.', '.', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "print(f'predicted trg = {translation}')\n",
    "\n",
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "# Usually, BLEU is calculated over multiple candidate translations per source and target sentence (reference)\n",
    "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
    "    # stores targets\n",
    "    trgs = []\n",
    "    # stores predictions (candidate per target)\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for datum in data:\n",
    "        \n",
    "        src = vars(datum)['src']\n",
    "        trg = vars(datum)['trg']\n",
    "        # get translation candidate\n",
    "        # max_len defines the maximum length of translation\n",
    "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
    "        \n",
    "        #cut off <eos> token\n",
    "        pred_trg = pred_trg[:-1]\n",
    "        \n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "        \n",
    "    return bleu_score(pred_trgs, trgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most useful part of a BLEU score is that it can be used to compare different models on the same dataset, where the one with the higher BLEU score is \"better\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 30.63\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n",
    "\n",
    "print(f'BLEU score = {bleu_score*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
